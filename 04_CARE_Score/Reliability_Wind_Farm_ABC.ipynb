{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9f2775-c3b5-44b7-8379-24a933497a71",
   "metadata": {},
   "source": [
    "## Reliability Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecfcfc9-8598-448d-bd6c-8c7d8c2c80a0",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08dc247-5714-4a29-b3bb-526c256df294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bda083-2537-4da8-b7b7-9404a07fcae0",
   "metadata": {},
   "source": [
    "## Wind Farm A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8ab611-2e76-4731-b221-36dfd84b5f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'Data Set', 'Event', 'Event Start ID', 'Event End ID'], dtype='object')\n",
      "🛑 Dataset 0 → Predicted: ABNORMAL | Criticality = 436\n",
      "✅ Dataset 3 → Predicted: NORMAL | Criticality = 20\n",
      "✅ Dataset 10 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 13 → Predicted: NORMAL | Criticality = 38\n",
      "✅ Dataset 14 → Predicted: NORMAL | Criticality = 46\n",
      "✅ Dataset 17 → Predicted: NORMAL | Criticality = 54\n",
      "✅ Dataset 22 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 24 → Predicted: NORMAL | Criticality = 44\n",
      "✅ Dataset 25 → Predicted: NORMAL | Criticality = 9\n",
      "🛑 Dataset 26 → Predicted: ABNORMAL | Criticality = 106\n",
      "✅ Dataset 38 → Predicted: NORMAL | Criticality = 34\n",
      "🛑 Dataset 40 → Predicted: ABNORMAL | Criticality = 141\n",
      "✅ Dataset 42 → Predicted: NORMAL | Criticality = 19\n",
      "✅ Dataset 45 → Predicted: NORMAL | Criticality = 68\n",
      "✅ Dataset 51 → Predicted: NORMAL | Criticality = 10\n",
      "✅ Dataset 68 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 69 → Predicted: NORMAL | Criticality = 30\n",
      "✅ Dataset 71 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 72 → Predicted: NORMAL | Criticality = 28\n",
      "🛑 Dataset 73 → Predicted: ABNORMAL | Criticality = 72\n",
      "🛑 Dataset 84 → Predicted: ABNORMAL | Criticality = 76\n",
      "✅ Dataset 92 → Predicted: NORMAL | Criticality = 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === File paths ===\n",
    "excel_events_path = r\"D:\\Master Thesis New Data Set\\Wind Farm Events\\Wind Farm A.xlsx\"  # <-- Update this to the actual path to your Excel\n",
    "gt_base_path = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm A\\Wind Farm A\\datasets\"\n",
    "pred_base_path = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm A\"\n",
    "\n",
    "# === Constants ===\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "criticality_threshold = 72  # per author\n",
    "\n",
    "# === Load event metadata from Excel ===\n",
    "events_df = pd.read_excel(excel_events_path)\n",
    "print(events_df.columns)\n",
    "\n",
    "\n",
    "# === Loop through each dataset in Excel ===\n",
    "for _, row in events_df.iterrows():\n",
    "    dataset_id = int(row['Data Set'])\n",
    "    event_start = row['Event Start ID']\n",
    "    event_end = row['Event End ID']\n",
    "    is_abnormal_event = row['Event'].strip().lower() == 'Abnormal'\n",
    "\n",
    "    ground_truth_path = os.path.join(gt_base_path, f\"{dataset_id}.csv\")\n",
    "    predicted_path = os.path.join(pred_base_path, f\"{dataset_id}_WindFarm_A_predictions_lgb_smoothed.csv\")\n",
    "\n",
    "    try:\n",
    "        gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(predicted_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Missing file(s) for dataset {dataset_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    def map_to_binary_status(x):\n",
    "        if x == normal_status_id:\n",
    "            return 1\n",
    "        elif x in abnormal_status_ids:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1  # Treat unknowns as normal\n",
    "\n",
    "    gt_df['adjusted_status'] = gt_df['status_type_id'].apply(map_to_binary_status)\n",
    "\n",
    "    # Apply override within event window\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'adjusted_status'] = 0 if is_abnormal_event else 1\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'adjusted_status']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 0 if x == normal_status_id else 1\n",
    "    )\n",
    "\n",
    "    def calculate_criticality(gt_statuses, predictions):\n",
    "        crit = np.zeros(len(gt_statuses) + 1, dtype=int)\n",
    "        for i in range(len(gt_statuses)):\n",
    "            if gt_statuses[i] == 0:\n",
    "                if predictions[i] == 1:\n",
    "                    crit[i + 1] = crit[i] + 1\n",
    "                else:\n",
    "                    crit[i + 1] = max(crit[i] - 1, 0)\n",
    "            else:\n",
    "                crit[i + 1] = crit[i]\n",
    "        return crit[1:]\n",
    "\n",
    "    criticality = calculate_criticality(\n",
    "        merged_df['adjusted_status'].values,\n",
    "        merged_df['pred_label'].values\n",
    "    )\n",
    "    max_crit = np.max(criticality)\n",
    "\n",
    "    # === Final classification ===\n",
    "    if max_crit >= criticality_threshold:\n",
    "        print(f\"🛑 Dataset {dataset_id} → Predicted: ABNORMAL | Criticality = {max_crit}\")\n",
    "    else:\n",
    "        print(f\"✅ Dataset {dataset_id} → Predicted: NORMAL | Criticality = {max_crit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74131fe5-42a8-4d83-8357-43c3bb7576c2",
   "metadata": {},
   "source": [
    "## Score Wind Farm A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2f3ceb-2de7-41f9-8e88-b301bc3b3014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta score (beta=0.5): 0.8065\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Actual Event vs Light GBM prediction data\n",
    "data = {\n",
    "    'Event': [\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal',\n",
    "        'Abnormal', 'Normal'\n",
    "    ],\n",
    "    'Light GBM': [\n",
    "        'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal','Normal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal','Normal', 'Abnormal',\n",
    "       'Abnormal', 'Normal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map labels to binary: Abnormal = 1, Normal = 0\n",
    "label_map = {'Abnormal': 1, 'Normal': 0}\n",
    "y_true = df['Event'].map(label_map)\n",
    "y_pred = df['Light GBM'].map(label_map)\n",
    "\n",
    "# Compute F-beta score (beta = 0.5)\n",
    "beta = 0.5\n",
    "f_beta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Output result\n",
    "print(f\"F-beta score (beta={beta}): {f_beta:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6b41e-2c8b-4fd6-bf24-caef9f294f5f",
   "metadata": {},
   "source": [
    "## Wind Farm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791eed3f-896c-4561-8a86-c93b10ba1791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'Data Set', 'Event', 'Event Start ID', 'Event End ID'], dtype='object')\n",
      "✅ Dataset 2 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 7 → Predicted: NORMAL | Criticality = 63\n",
      "✅ Dataset 19 → Predicted: NORMAL | Criticality = 23\n",
      "✅ Dataset 21 → Predicted: NORMAL | Criticality = 0\n",
      "🛑 Dataset 23 → Predicted: ABNORMAL | Criticality = 157\n",
      "🛑 Dataset 27 → Predicted: ABNORMAL | Criticality = 864\n",
      "✅ Dataset 34 → Predicted: NORMAL | Criticality = 21\n",
      "✅ Dataset 52 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 53 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 74 → Predicted: NORMAL | Criticality = 0\n",
      "🛑 Dataset 77 → Predicted: ABNORMAL | Criticality = 215\n",
      "✅ Dataset 82 → Predicted: NORMAL | Criticality = 2\n",
      "✅ Dataset 83 → Predicted: NORMAL | Criticality = 50\n",
      "✅ Dataset 86 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 87 → Predicted: NORMAL | Criticality = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === File paths ===\n",
    "excel_events_path = r\"D:\\Master Thesis New Data Set\\Wind Farm Events\\Wind Farm B.xlsx\"  # <-- Update this to the actual path to your Excel\n",
    "gt_base_path = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm B\\Wind Farm B\\datasets\"\n",
    "pred_base_path = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm B\"\n",
    "\n",
    "# === Constants ===\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "criticality_threshold = 72  # per author\n",
    "\n",
    "# === Load event metadata from Excel ===\n",
    "events_df = pd.read_excel(excel_events_path)\n",
    "print(events_df.columns)\n",
    "\n",
    "\n",
    "# === Loop through each dataset in Excel ===\n",
    "for _, row in events_df.iterrows():\n",
    "    dataset_id = int(row['Data Set'])\n",
    "    event_start = row['Event Start ID']\n",
    "    event_end = row['Event End ID']\n",
    "    is_abnormal_event = row['Event'].strip().lower() == 'Abnormal'\n",
    "\n",
    "    ground_truth_path = os.path.join(gt_base_path, f\"{dataset_id}.csv\")\n",
    "    predicted_path = os.path.join(pred_base_path, f\"{dataset_id}_WindFarm_B_predictions_lgb_smoothed.csv\")\n",
    "\n",
    "    try:\n",
    "        gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(predicted_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Missing file(s) for dataset {dataset_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    def map_to_binary_status(x):\n",
    "        if x == normal_status_id:\n",
    "            return 1\n",
    "        elif x in abnormal_status_ids:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1  # Treat unknowns as normal\n",
    "\n",
    "    gt_df['adjusted_status'] = gt_df['status_type_id'].apply(map_to_binary_status)\n",
    "\n",
    "    # Apply override within event window\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'adjusted_status'] = 0 if is_abnormal_event else 1\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'adjusted_status']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 0 if x == normal_status_id else 1\n",
    "    )\n",
    "\n",
    "    def calculate_criticality(gt_statuses, predictions):\n",
    "        crit = np.zeros(len(gt_statuses) + 1, dtype=int)\n",
    "        for i in range(len(gt_statuses)):\n",
    "            if gt_statuses[i] == 0:\n",
    "                if predictions[i] == 1:\n",
    "                    crit[i + 1] = crit[i] + 1\n",
    "                else:\n",
    "                    crit[i + 1] = max(crit[i] - 1, 0)\n",
    "            else:\n",
    "                crit[i + 1] = crit[i]\n",
    "        return crit[1:]\n",
    "\n",
    "    criticality = calculate_criticality(\n",
    "        merged_df['adjusted_status'].values,\n",
    "        merged_df['pred_label'].values\n",
    "    )\n",
    "    max_crit = np.max(criticality)\n",
    "\n",
    "    # === Final classification ===\n",
    "    if max_crit >= criticality_threshold:\n",
    "        print(f\"🛑 Dataset {dataset_id} → Predicted: ABNORMAL | Criticality = {max_crit}\")\n",
    "    else:\n",
    "        print(f\"✅ Dataset {dataset_id} → Predicted: NORMAL | Criticality = {max_crit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd48b08-1b14-4586-8da6-33456bc17d8e",
   "metadata": {},
   "source": [
    "## Score Wind Farm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0d432f-2126-4272-a582-ecfeee5a7039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta score (beta=0.5): 0.5556\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Actual Event vs Light GBM prediction data\n",
    "data = {\n",
    "    'Event': [\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal',  'Normal', 'Normal', 'Normal',\n",
    "        'Normal'\n",
    "    ],\n",
    "    'Light GBM': [\n",
    "        'Normal', 'Normal', 'Normal', 'Normal','Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal',\n",
    "        'Normal', 'Abnormal',  'Normal', 'Normal', 'Normal',\n",
    "        'Normal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map labels to binary: Abnormal = 1, Normal = 0\n",
    "label_map = {'Abnormal': 1, 'Normal': 0}\n",
    "y_true = df['Event'].map(label_map)\n",
    "y_pred = df['Light GBM'].map(label_map)\n",
    "\n",
    "# Compute F-beta score (beta = 0.5)\n",
    "beta = 0.5\n",
    "f_beta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Output result\n",
    "print(f\"F-beta score (beta={beta}): {f_beta:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a3794-e2da-4e5e-8dee-be38c72986b3",
   "metadata": {},
   "source": [
    "## Wind Farm C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1628c0d8-c304-4def-9286-63e500e9a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'Data Set', 'Event', 'Event Start ID', 'Event End ID'], dtype='object')\n",
      "✅ Dataset 1 → Predicted: NORMAL | Criticality = 1\n",
      "🛑 Dataset 4 → Predicted: ABNORMAL | Criticality = 212\n",
      "🛑 Dataset 5 → Predicted: ABNORMAL | Criticality = 74\n",
      "✅ Dataset 6 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 8 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 9 → Predicted: NORMAL | Criticality = 5\n",
      "🛑 Dataset 11 → Predicted: ABNORMAL | Criticality = 864\n",
      "✅ Dataset 12 → Predicted: NORMAL | Criticality = 4\n",
      "✅ Dataset 15 → Predicted: NORMAL | Criticality = 2\n",
      "✅ Dataset 16 → Predicted: NORMAL | Criticality = 0\n",
      "🛑 Dataset 18 → Predicted: ABNORMAL | Criticality = 581\n",
      "✅ Dataset 20 → Predicted: NORMAL | Criticality = 0\n",
      "🛑 Dataset 28 → Predicted: ABNORMAL | Criticality = 119\n",
      "✅ Dataset 29 → Predicted: NORMAL | Criticality = 1\n",
      "✅ Dataset 30 → Predicted: NORMAL | Criticality = 3\n",
      "✅ Dataset 31 → Predicted: NORMAL | Criticality = 1\n",
      "✅ Dataset 32 → Predicted: NORMAL | Criticality = 1\n",
      "🛑 Dataset 33 → Predicted: ABNORMAL | Criticality = 126\n",
      "🛑 Dataset 35 → Predicted: ABNORMAL | Criticality = 230\n",
      "✅ Dataset 36 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 37 → Predicted: NORMAL | Criticality = 8\n",
      "✅ Dataset 39 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 41 → Predicted: NORMAL | Criticality = 3\n",
      "✅ Dataset 43 → Predicted: NORMAL | Criticality = 0\n",
      "🛑 Dataset 44 → Predicted: ABNORMAL | Criticality = 326\n",
      "✅ Dataset 46 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 47 → Predicted: NORMAL | Criticality = 17\n",
      "✅ Dataset 48 → Predicted: NORMAL | Criticality = 0\n",
      "🛑 Dataset 49 → Predicted: ABNORMAL | Criticality = 460\n",
      "✅ Dataset 50 → Predicted: NORMAL | Criticality = 3\n",
      "✅ Dataset 54 → Predicted: NORMAL | Criticality = 15\n",
      "✅ Dataset 55 → Predicted: NORMAL | Criticality = 5\n",
      "✅ Dataset 56 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 57 → Predicted: NORMAL | Criticality = 15\n",
      "✅ Dataset 58 → Predicted: NORMAL | Criticality = 2\n",
      "✅ Dataset 59 → Predicted: NORMAL | Criticality = 1\n",
      "✅ Dataset 60 → Predicted: NORMAL | Criticality = 13\n",
      "✅ Dataset 61 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 62 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 63 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 64 → Predicted: NORMAL | Criticality = 2\n",
      "✅ Dataset 65 → Predicted: NORMAL | Criticality = 3\n",
      "✅ Dataset 66 → Predicted: NORMAL | Criticality = 28\n",
      "🛑 Dataset 67 → Predicted: ABNORMAL | Criticality = 72\n",
      "✅ Dataset 70 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 75 → Predicted: NORMAL | Criticality = 62\n",
      "🛑 Dataset 76 → Predicted: ABNORMAL | Criticality = 98\n",
      "✅ Dataset 78 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 79 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 80 → Predicted: NORMAL | Criticality = 1\n",
      "✅ Dataset 81 → Predicted: NORMAL | Criticality = 0\n",
      "✅ Dataset 85 → Predicted: NORMAL | Criticality = 4\n",
      "✅ Dataset 88 → Predicted: NORMAL | Criticality = 30\n",
      "✅ Dataset 89 → Predicted: NORMAL | Criticality = 0\n",
      "🛑 Dataset 90 → Predicted: ABNORMAL | Criticality = 106\n",
      "✅ Dataset 91 → Predicted: NORMAL | Criticality = 54\n",
      "✅ Dataset 93 → Predicted: NORMAL | Criticality = 0\n",
      "🛑 Dataset 94 → Predicted: ABNORMAL | Criticality = 111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === File paths ===\n",
    "excel_events_path = r\"D:\\Master Thesis New Data Set\\Wind Farm Events\\Wind Farm C.xlsx\"  # <-- Update this to the actual path to your Excel\n",
    "gt_base_path = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm C\\Wind Farm C\\datasets\"\n",
    "pred_base_path = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm C\"\n",
    "\n",
    "# === Constants ===\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "criticality_threshold = 72  # per author\n",
    "\n",
    "# === Load event metadata from Excel ===\n",
    "events_df = pd.read_excel(excel_events_path)\n",
    "print(events_df.columns)\n",
    "\n",
    "\n",
    "# === Loop through each dataset in Excel ===\n",
    "for _, row in events_df.iterrows():\n",
    "    dataset_id = int(row['Data Set'])\n",
    "    event_start = row['Event Start ID']\n",
    "    event_end = row['Event End ID']\n",
    "    is_abnormal_event = row['Event'].strip().lower() == 'Abnormal'\n",
    "\n",
    "    ground_truth_path = os.path.join(gt_base_path, f\"{dataset_id}.csv\")\n",
    "    predicted_path = os.path.join(pred_base_path, f\"{dataset_id}_WindFarm_C_predictions_lgb_smoothed.csv\")\n",
    "\n",
    "    try:\n",
    "        gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(predicted_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Missing file(s) for dataset {dataset_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    def map_to_binary_status(x):\n",
    "        if x == normal_status_id:\n",
    "            return 1\n",
    "        elif x in abnormal_status_ids:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1  # Treat unknowns as normal\n",
    "\n",
    "    gt_df['adjusted_status'] = gt_df['status_type_id'].apply(map_to_binary_status)\n",
    "\n",
    "    # Apply override within event window\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'adjusted_status'] = 0 if is_abnormal_event else 1\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'adjusted_status']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 0 if x == normal_status_id else 1\n",
    "    )\n",
    "\n",
    "    def calculate_criticality(gt_statuses, predictions):\n",
    "        crit = np.zeros(len(gt_statuses) + 1, dtype=int)\n",
    "        for i in range(len(gt_statuses)):\n",
    "            if gt_statuses[i] == 0:\n",
    "                if predictions[i] == 1:\n",
    "                    crit[i + 1] = crit[i] + 1\n",
    "                else:\n",
    "                    crit[i + 1] = max(crit[i] - 1, 0)\n",
    "            else:\n",
    "                crit[i + 1] = crit[i]\n",
    "        return crit[1:]\n",
    "\n",
    "    criticality = calculate_criticality(\n",
    "        merged_df['adjusted_status'].values,\n",
    "        merged_df['pred_label'].values\n",
    "    )\n",
    "    max_crit = np.max(criticality)\n",
    "\n",
    "    # === Final classification ===\n",
    "    if max_crit >= criticality_threshold:\n",
    "        print(f\"🛑 Dataset {dataset_id} → Predicted: ABNORMAL | Criticality = {max_crit}\")\n",
    "    else:\n",
    "        print(f\"✅ Dataset {dataset_id} → Predicted: NORMAL | Criticality = {max_crit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7ee00-b4bc-4aeb-8fd7-10c669831769",
   "metadata": {},
   "source": [
    "## Score Wind Farm C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18498d1-4cfe-42b2-945d-ae20d75df6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta score (beta=0.5): 0.7595\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "\n",
    "# Actual Event vs Light GBM prediction data\n",
    "data = {\n",
    "    'Event': [\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal',\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal',\n",
    "        'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal',\n",
    "        'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal'\n",
    "    ],\n",
    "    'Light GBM': [\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal','Normal',\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Abnormal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map labels to binary: Abnormal = 1, Normal = 0\n",
    "label_map = {'Abnormal': 1, 'Normal': 0}\n",
    "y_true = df['Event'].map(label_map)\n",
    "y_pred = df['Light GBM'].map(label_map)\n",
    "\n",
    "# Compute F-beta score (beta = 0.5)\n",
    "beta = 0.5\n",
    "f_beta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Output result\n",
    "print(f\"F-beta score (beta={beta}): {f_beta:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328eff4-e948-4a1c-a2f0-6d1838eb6b11",
   "metadata": {},
   "source": [
    "## Overall Reliability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c830758-03a4-4722-a8ef-37a17a58769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta score (beta=0.5): 0.7422\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Actual Event vs Light GBM prediction data\n",
    "data = {\n",
    "    'Event': [\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal',\n",
    "        'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal',  'Normal', 'Normal', 'Normal',\n",
    "        'Normal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal',\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal',\n",
    "        'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal',\n",
    "        'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal'\n",
    "        \n",
    "    ],\n",
    "    'Light GBM': [\n",
    "        'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal',\n",
    "        'Abnormal', 'Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal','Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal',\n",
    "        'Normal', 'Abnormal',  'Normal', 'Normal', 'Normal',\n",
    "        'Normal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal','Normal',\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Abnormal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map labels to binary: Abnormal = 1, Normal = 0\n",
    "label_map = {'Abnormal': 1, 'Normal': 0}\n",
    "y_true = df['Event'].map(label_map)\n",
    "y_pred = df['Light GBM'].map(label_map)\n",
    "\n",
    "# Compute F-beta score (beta = 0.5)\n",
    "beta = 0.5\n",
    "f_beta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Output result\n",
    "print(f\"F-beta score (beta={beta}): {f_beta:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
