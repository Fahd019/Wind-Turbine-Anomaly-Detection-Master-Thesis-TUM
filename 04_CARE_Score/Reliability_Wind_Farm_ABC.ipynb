{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9f2775-c3b5-44b7-8379-24a933497a71",
   "metadata": {},
   "source": [
    "## Reliability Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecfcfc9-8598-448d-bd6c-8c7d8c2c80a0",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08dc247-5714-4a29-b3bb-526c256df294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bda083-2537-4da8-b7b7-9404a07fcae0",
   "metadata": {},
   "source": [
    "## Wind Farm A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8ab611-2e76-4731-b221-36dfd84b5f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'Data Set', 'Event', 'Event Start ID', 'Event End ID'], dtype='object')\n",
      "ðŸ›‘ Dataset 0 â†’ Predicted: ABNORMAL | Criticality = 436\n",
      "âœ… Dataset 3 â†’ Predicted: NORMAL | Criticality = 20\n",
      "âœ… Dataset 10 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 13 â†’ Predicted: NORMAL | Criticality = 38\n",
      "âœ… Dataset 14 â†’ Predicted: NORMAL | Criticality = 46\n",
      "âœ… Dataset 17 â†’ Predicted: NORMAL | Criticality = 54\n",
      "âœ… Dataset 22 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 24 â†’ Predicted: NORMAL | Criticality = 44\n",
      "âœ… Dataset 25 â†’ Predicted: NORMAL | Criticality = 9\n",
      "ðŸ›‘ Dataset 26 â†’ Predicted: ABNORMAL | Criticality = 106\n",
      "âœ… Dataset 38 â†’ Predicted: NORMAL | Criticality = 34\n",
      "ðŸ›‘ Dataset 40 â†’ Predicted: ABNORMAL | Criticality = 141\n",
      "âœ… Dataset 42 â†’ Predicted: NORMAL | Criticality = 19\n",
      "âœ… Dataset 45 â†’ Predicted: NORMAL | Criticality = 68\n",
      "âœ… Dataset 51 â†’ Predicted: NORMAL | Criticality = 10\n",
      "âœ… Dataset 68 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 69 â†’ Predicted: NORMAL | Criticality = 30\n",
      "âœ… Dataset 71 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 72 â†’ Predicted: NORMAL | Criticality = 28\n",
      "ðŸ›‘ Dataset 73 â†’ Predicted: ABNORMAL | Criticality = 72\n",
      "ðŸ›‘ Dataset 84 â†’ Predicted: ABNORMAL | Criticality = 76\n",
      "âœ… Dataset 92 â†’ Predicted: NORMAL | Criticality = 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === File paths ===\n",
    "excel_events_path = r\"D:\\Master Thesis New Data Set\\Wind Farm Events\\Wind Farm A.xlsx\"  # <-- Update this to the actual path to your Excel\n",
    "gt_base_path = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm A\\Wind Farm A\\datasets\"\n",
    "pred_base_path = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm A\"\n",
    "\n",
    "# === Constants ===\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "criticality_threshold = 72  # per author\n",
    "\n",
    "# === Load event metadata from Excel ===\n",
    "events_df = pd.read_excel(excel_events_path)\n",
    "print(events_df.columns)\n",
    "\n",
    "\n",
    "# === Loop through each dataset in Excel ===\n",
    "for _, row in events_df.iterrows():\n",
    "    dataset_id = int(row['Data Set'])\n",
    "    event_start = row['Event Start ID']\n",
    "    event_end = row['Event End ID']\n",
    "    is_abnormal_event = row['Event'].strip().lower() == 'Abnormal'\n",
    "\n",
    "    ground_truth_path = os.path.join(gt_base_path, f\"{dataset_id}.csv\")\n",
    "    predicted_path = os.path.join(pred_base_path, f\"{dataset_id}_WindFarm_A_predictions_lgb_smoothed.csv\")\n",
    "\n",
    "    try:\n",
    "        gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(predicted_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸ Missing file(s) for dataset {dataset_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    def map_to_binary_status(x):\n",
    "        if x == normal_status_id:\n",
    "            return 1\n",
    "        elif x in abnormal_status_ids:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1  # Treat unknowns as normal\n",
    "\n",
    "    gt_df['adjusted_status'] = gt_df['status_type_id'].apply(map_to_binary_status)\n",
    "\n",
    "    # Apply override within event window\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'adjusted_status'] = 0 if is_abnormal_event else 1\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'adjusted_status']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 0 if x == normal_status_id else 1\n",
    "    )\n",
    "\n",
    "    def calculate_criticality(gt_statuses, predictions):\n",
    "        crit = np.zeros(len(gt_statuses) + 1, dtype=int)\n",
    "        for i in range(len(gt_statuses)):\n",
    "            if gt_statuses[i] == 0:\n",
    "                if predictions[i] == 1:\n",
    "                    crit[i + 1] = crit[i] + 1\n",
    "                else:\n",
    "                    crit[i + 1] = max(crit[i] - 1, 0)\n",
    "            else:\n",
    "                crit[i + 1] = crit[i]\n",
    "        return crit[1:]\n",
    "\n",
    "    criticality = calculate_criticality(\n",
    "        merged_df['adjusted_status'].values,\n",
    "        merged_df['pred_label'].values\n",
    "    )\n",
    "    max_crit = np.max(criticality)\n",
    "\n",
    "    # === Final classification ===\n",
    "    if max_crit >= criticality_threshold:\n",
    "        print(f\"ðŸ›‘ Dataset {dataset_id} â†’ Predicted: ABNORMAL | Criticality = {max_crit}\")\n",
    "    else:\n",
    "        print(f\"âœ… Dataset {dataset_id} â†’ Predicted: NORMAL | Criticality = {max_crit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74131fe5-42a8-4d83-8357-43c3bb7576c2",
   "metadata": {},
   "source": [
    "## Score Wind Farm A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2f3ceb-2de7-41f9-8e88-b301bc3b3014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta score (beta=0.5): 0.8065\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Actual Event vs Light GBM prediction data\n",
    "data = {\n",
    "    'Event': [\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal',\n",
    "        'Abnormal', 'Normal'\n",
    "    ],\n",
    "    'Light GBM': [\n",
    "        'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal','Normal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal','Normal', 'Abnormal',\n",
    "       'Abnormal', 'Normal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map labels to binary: Abnormal = 1, Normal = 0\n",
    "label_map = {'Abnormal': 1, 'Normal': 0}\n",
    "y_true = df['Event'].map(label_map)\n",
    "y_pred = df['Light GBM'].map(label_map)\n",
    "\n",
    "# Compute F-beta score (beta = 0.5)\n",
    "beta = 0.5\n",
    "f_beta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Output result\n",
    "print(f\"F-beta score (beta={beta}): {f_beta:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6b41e-2c8b-4fd6-bf24-caef9f294f5f",
   "metadata": {},
   "source": [
    "## Wind Farm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791eed3f-896c-4561-8a86-c93b10ba1791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'Data Set', 'Event', 'Event Start ID', 'Event End ID'], dtype='object')\n",
      "âœ… Dataset 2 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 7 â†’ Predicted: NORMAL | Criticality = 63\n",
      "âœ… Dataset 19 â†’ Predicted: NORMAL | Criticality = 23\n",
      "âœ… Dataset 21 â†’ Predicted: NORMAL | Criticality = 0\n",
      "ðŸ›‘ Dataset 23 â†’ Predicted: ABNORMAL | Criticality = 157\n",
      "ðŸ›‘ Dataset 27 â†’ Predicted: ABNORMAL | Criticality = 864\n",
      "âœ… Dataset 34 â†’ Predicted: NORMAL | Criticality = 21\n",
      "âœ… Dataset 52 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 53 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 74 â†’ Predicted: NORMAL | Criticality = 0\n",
      "ðŸ›‘ Dataset 77 â†’ Predicted: ABNORMAL | Criticality = 215\n",
      "âœ… Dataset 82 â†’ Predicted: NORMAL | Criticality = 2\n",
      "âœ… Dataset 83 â†’ Predicted: NORMAL | Criticality = 50\n",
      "âœ… Dataset 86 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 87 â†’ Predicted: NORMAL | Criticality = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === File paths ===\n",
    "excel_events_path = r\"D:\\Master Thesis New Data Set\\Wind Farm Events\\Wind Farm B.xlsx\"  # <-- Update this to the actual path to your Excel\n",
    "gt_base_path = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm B\\Wind Farm B\\datasets\"\n",
    "pred_base_path = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm B\"\n",
    "\n",
    "# === Constants ===\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "criticality_threshold = 72  # per author\n",
    "\n",
    "# === Load event metadata from Excel ===\n",
    "events_df = pd.read_excel(excel_events_path)\n",
    "print(events_df.columns)\n",
    "\n",
    "\n",
    "# === Loop through each dataset in Excel ===\n",
    "for _, row in events_df.iterrows():\n",
    "    dataset_id = int(row['Data Set'])\n",
    "    event_start = row['Event Start ID']\n",
    "    event_end = row['Event End ID']\n",
    "    is_abnormal_event = row['Event'].strip().lower() == 'Abnormal'\n",
    "\n",
    "    ground_truth_path = os.path.join(gt_base_path, f\"{dataset_id}.csv\")\n",
    "    predicted_path = os.path.join(pred_base_path, f\"{dataset_id}_WindFarm_B_predictions_lgb_smoothed.csv\")\n",
    "\n",
    "    try:\n",
    "        gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(predicted_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸ Missing file(s) for dataset {dataset_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    def map_to_binary_status(x):\n",
    "        if x == normal_status_id:\n",
    "            return 1\n",
    "        elif x in abnormal_status_ids:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1  # Treat unknowns as normal\n",
    "\n",
    "    gt_df['adjusted_status'] = gt_df['status_type_id'].apply(map_to_binary_status)\n",
    "\n",
    "    # Apply override within event window\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'adjusted_status'] = 0 if is_abnormal_event else 1\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'adjusted_status']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 0 if x == normal_status_id else 1\n",
    "    )\n",
    "\n",
    "    def calculate_criticality(gt_statuses, predictions):\n",
    "        crit = np.zeros(len(gt_statuses) + 1, dtype=int)\n",
    "        for i in range(len(gt_statuses)):\n",
    "            if gt_statuses[i] == 0:\n",
    "                if predictions[i] == 1:\n",
    "                    crit[i + 1] = crit[i] + 1\n",
    "                else:\n",
    "                    crit[i + 1] = max(crit[i] - 1, 0)\n",
    "            else:\n",
    "                crit[i + 1] = crit[i]\n",
    "        return crit[1:]\n",
    "\n",
    "    criticality = calculate_criticality(\n",
    "        merged_df['adjusted_status'].values,\n",
    "        merged_df['pred_label'].values\n",
    "    )\n",
    "    max_crit = np.max(criticality)\n",
    "\n",
    "    # === Final classification ===\n",
    "    if max_crit >= criticality_threshold:\n",
    "        print(f\"ðŸ›‘ Dataset {dataset_id} â†’ Predicted: ABNORMAL | Criticality = {max_crit}\")\n",
    "    else:\n",
    "        print(f\"âœ… Dataset {dataset_id} â†’ Predicted: NORMAL | Criticality = {max_crit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd48b08-1b14-4586-8da6-33456bc17d8e",
   "metadata": {},
   "source": [
    "## Score Wind Farm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0d432f-2126-4272-a582-ecfeee5a7039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta score (beta=0.5): 0.5556\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Actual Event vs Light GBM prediction data\n",
    "data = {\n",
    "    'Event': [\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal',  'Normal', 'Normal', 'Normal',\n",
    "        'Normal'\n",
    "    ],\n",
    "    'Light GBM': [\n",
    "        'Normal', 'Normal', 'Normal', 'Normal','Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal',\n",
    "        'Normal', 'Abnormal',  'Normal', 'Normal', 'Normal',\n",
    "        'Normal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map labels to binary: Abnormal = 1, Normal = 0\n",
    "label_map = {'Abnormal': 1, 'Normal': 0}\n",
    "y_true = df['Event'].map(label_map)\n",
    "y_pred = df['Light GBM'].map(label_map)\n",
    "\n",
    "# Compute F-beta score (beta = 0.5)\n",
    "beta = 0.5\n",
    "f_beta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Output result\n",
    "print(f\"F-beta score (beta={beta}): {f_beta:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a3794-e2da-4e5e-8dee-be38c72986b3",
   "metadata": {},
   "source": [
    "## Wind Farm C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1628c0d8-c304-4def-9286-63e500e9a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'Data Set', 'Event', 'Event Start ID', 'Event End ID'], dtype='object')\n",
      "âœ… Dataset 1 â†’ Predicted: NORMAL | Criticality = 1\n",
      "ðŸ›‘ Dataset 4 â†’ Predicted: ABNORMAL | Criticality = 212\n",
      "ðŸ›‘ Dataset 5 â†’ Predicted: ABNORMAL | Criticality = 74\n",
      "âœ… Dataset 6 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 8 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 9 â†’ Predicted: NORMAL | Criticality = 5\n",
      "ðŸ›‘ Dataset 11 â†’ Predicted: ABNORMAL | Criticality = 864\n",
      "âœ… Dataset 12 â†’ Predicted: NORMAL | Criticality = 4\n",
      "âœ… Dataset 15 â†’ Predicted: NORMAL | Criticality = 2\n",
      "âœ… Dataset 16 â†’ Predicted: NORMAL | Criticality = 0\n",
      "ðŸ›‘ Dataset 18 â†’ Predicted: ABNORMAL | Criticality = 581\n",
      "âœ… Dataset 20 â†’ Predicted: NORMAL | Criticality = 0\n",
      "ðŸ›‘ Dataset 28 â†’ Predicted: ABNORMAL | Criticality = 119\n",
      "âœ… Dataset 29 â†’ Predicted: NORMAL | Criticality = 1\n",
      "âœ… Dataset 30 â†’ Predicted: NORMAL | Criticality = 3\n",
      "âœ… Dataset 31 â†’ Predicted: NORMAL | Criticality = 1\n",
      "âœ… Dataset 32 â†’ Predicted: NORMAL | Criticality = 1\n",
      "ðŸ›‘ Dataset 33 â†’ Predicted: ABNORMAL | Criticality = 126\n",
      "ðŸ›‘ Dataset 35 â†’ Predicted: ABNORMAL | Criticality = 230\n",
      "âœ… Dataset 36 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 37 â†’ Predicted: NORMAL | Criticality = 8\n",
      "âœ… Dataset 39 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 41 â†’ Predicted: NORMAL | Criticality = 3\n",
      "âœ… Dataset 43 â†’ Predicted: NORMAL | Criticality = 0\n",
      "ðŸ›‘ Dataset 44 â†’ Predicted: ABNORMAL | Criticality = 326\n",
      "âœ… Dataset 46 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 47 â†’ Predicted: NORMAL | Criticality = 17\n",
      "âœ… Dataset 48 â†’ Predicted: NORMAL | Criticality = 0\n",
      "ðŸ›‘ Dataset 49 â†’ Predicted: ABNORMAL | Criticality = 460\n",
      "âœ… Dataset 50 â†’ Predicted: NORMAL | Criticality = 3\n",
      "âœ… Dataset 54 â†’ Predicted: NORMAL | Criticality = 15\n",
      "âœ… Dataset 55 â†’ Predicted: NORMAL | Criticality = 5\n",
      "âœ… Dataset 56 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 57 â†’ Predicted: NORMAL | Criticality = 15\n",
      "âœ… Dataset 58 â†’ Predicted: NORMAL | Criticality = 2\n",
      "âœ… Dataset 59 â†’ Predicted: NORMAL | Criticality = 1\n",
      "âœ… Dataset 60 â†’ Predicted: NORMAL | Criticality = 13\n",
      "âœ… Dataset 61 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 62 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 63 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 64 â†’ Predicted: NORMAL | Criticality = 2\n",
      "âœ… Dataset 65 â†’ Predicted: NORMAL | Criticality = 3\n",
      "âœ… Dataset 66 â†’ Predicted: NORMAL | Criticality = 28\n",
      "ðŸ›‘ Dataset 67 â†’ Predicted: ABNORMAL | Criticality = 72\n",
      "âœ… Dataset 70 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 75 â†’ Predicted: NORMAL | Criticality = 62\n",
      "ðŸ›‘ Dataset 76 â†’ Predicted: ABNORMAL | Criticality = 98\n",
      "âœ… Dataset 78 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 79 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 80 â†’ Predicted: NORMAL | Criticality = 1\n",
      "âœ… Dataset 81 â†’ Predicted: NORMAL | Criticality = 0\n",
      "âœ… Dataset 85 â†’ Predicted: NORMAL | Criticality = 4\n",
      "âœ… Dataset 88 â†’ Predicted: NORMAL | Criticality = 30\n",
      "âœ… Dataset 89 â†’ Predicted: NORMAL | Criticality = 0\n",
      "ðŸ›‘ Dataset 90 â†’ Predicted: ABNORMAL | Criticality = 106\n",
      "âœ… Dataset 91 â†’ Predicted: NORMAL | Criticality = 54\n",
      "âœ… Dataset 93 â†’ Predicted: NORMAL | Criticality = 0\n",
      "ðŸ›‘ Dataset 94 â†’ Predicted: ABNORMAL | Criticality = 111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === File paths ===\n",
    "excel_events_path = r\"D:\\Master Thesis New Data Set\\Wind Farm Events\\Wind Farm C.xlsx\"  # <-- Update this to the actual path to your Excel\n",
    "gt_base_path = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm C\\Wind Farm C\\datasets\"\n",
    "pred_base_path = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm C\"\n",
    "\n",
    "# === Constants ===\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "criticality_threshold = 72  # per author\n",
    "\n",
    "# === Load event metadata from Excel ===\n",
    "events_df = pd.read_excel(excel_events_path)\n",
    "print(events_df.columns)\n",
    "\n",
    "\n",
    "# === Loop through each dataset in Excel ===\n",
    "for _, row in events_df.iterrows():\n",
    "    dataset_id = int(row['Data Set'])\n",
    "    event_start = row['Event Start ID']\n",
    "    event_end = row['Event End ID']\n",
    "    is_abnormal_event = row['Event'].strip().lower() == 'Abnormal'\n",
    "\n",
    "    ground_truth_path = os.path.join(gt_base_path, f\"{dataset_id}.csv\")\n",
    "    predicted_path = os.path.join(pred_base_path, f\"{dataset_id}_WindFarm_C_predictions_lgb_smoothed.csv\")\n",
    "\n",
    "    try:\n",
    "        gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(predicted_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸ Missing file(s) for dataset {dataset_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    def map_to_binary_status(x):\n",
    "        if x == normal_status_id:\n",
    "            return 1\n",
    "        elif x in abnormal_status_ids:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1  # Treat unknowns as normal\n",
    "\n",
    "    gt_df['adjusted_status'] = gt_df['status_type_id'].apply(map_to_binary_status)\n",
    "\n",
    "    # Apply override within event window\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'adjusted_status'] = 0 if is_abnormal_event else 1\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'adjusted_status']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 0 if x == normal_status_id else 1\n",
    "    )\n",
    "\n",
    "    def calculate_criticality(gt_statuses, predictions):\n",
    "        crit = np.zeros(len(gt_statuses) + 1, dtype=int)\n",
    "        for i in range(len(gt_statuses)):\n",
    "            if gt_statuses[i] == 0:\n",
    "                if predictions[i] == 1:\n",
    "                    crit[i + 1] = crit[i] + 1\n",
    "                else:\n",
    "                    crit[i + 1] = max(crit[i] - 1, 0)\n",
    "            else:\n",
    "                crit[i + 1] = crit[i]\n",
    "        return crit[1:]\n",
    "\n",
    "    criticality = calculate_criticality(\n",
    "        merged_df['adjusted_status'].values,\n",
    "        merged_df['pred_label'].values\n",
    "    )\n",
    "    max_crit = np.max(criticality)\n",
    "\n",
    "    # === Final classification ===\n",
    "    if max_crit >= criticality_threshold:\n",
    "        print(f\"ðŸ›‘ Dataset {dataset_id} â†’ Predicted: ABNORMAL | Criticality = {max_crit}\")\n",
    "    else:\n",
    "        print(f\"âœ… Dataset {dataset_id} â†’ Predicted: NORMAL | Criticality = {max_crit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7ee00-b4bc-4aeb-8fd7-10c669831769",
   "metadata": {},
   "source": [
    "## Score Wind Farm C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18498d1-4cfe-42b2-945d-ae20d75df6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta score (beta=0.5): 0.7595\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "\n",
    "# Actual Event vs Light GBM prediction data\n",
    "data = {\n",
    "    'Event': [\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal',\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal',\n",
    "        'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal',\n",
    "        'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal'\n",
    "    ],\n",
    "    'Light GBM': [\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal','Normal',\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Abnormal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map labels to binary: Abnormal = 1, Normal = 0\n",
    "label_map = {'Abnormal': 1, 'Normal': 0}\n",
    "y_true = df['Event'].map(label_map)\n",
    "y_pred = df['Light GBM'].map(label_map)\n",
    "\n",
    "# Compute F-beta score (beta = 0.5)\n",
    "beta = 0.5\n",
    "f_beta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Output result\n",
    "print(f\"F-beta score (beta={beta}): {f_beta:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328eff4-e948-4a1c-a2f0-6d1838eb6b11",
   "metadata": {},
   "source": [
    "## Overall Reliability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c830758-03a4-4722-a8ef-37a17a58769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta score (beta=0.5): 0.7422\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Actual Event vs Light GBM prediction data\n",
    "data = {\n",
    "    'Event': [\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal',\n",
    "        'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal',  'Normal', 'Normal', 'Normal',\n",
    "        'Normal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal',\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Abnormal', 'Normal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal',\n",
    "        'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal',\n",
    "        'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal'\n",
    "        \n",
    "    ],\n",
    "    'Light GBM': [\n",
    "        'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal',\n",
    "        'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal',\n",
    "        'Abnormal', 'Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal','Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal',\n",
    "        'Normal', 'Abnormal',  'Normal', 'Normal', 'Normal',\n",
    "        'Normal',\n",
    "        'Normal', 'Abnormal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal','Normal',\n",
    "        'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Abnormal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Normal', 'Abnormal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal','Normal',\n",
    "        'Normal', 'Normal', 'Normal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map labels to binary: Abnormal = 1, Normal = 0\n",
    "label_map = {'Abnormal': 1, 'Normal': 0}\n",
    "y_true = df['Event'].map(label_map)\n",
    "y_pred = df['Light GBM'].map(label_map)\n",
    "\n",
    "# Compute F-beta score (beta = 0.5)\n",
    "beta = 0.5\n",
    "f_beta = fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n",
    "# Output result\n",
    "print(f\"F-beta score (beta={beta}): {f_beta:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
