{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9f2775-c3b5-44b7-8379-24a933497a71",
   "metadata": {},
   "source": [
    "## Accuracy Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e55a2e-1275-4414-8932-31deaac9c874",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62e8c04-97c2-4491-8c6a-f0ba5abc0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dedcb2-48da-4e22-ac74-29deeafd2fbc",
   "metadata": {},
   "source": [
    "## Wind Farm A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca78533-838f-47bf-8ad0-f8c8d683d429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 3 | Accuracy: 0.9227 | TN: 2518, FP: 211\n",
      "✅ Dataset 13 | Accuracy: 0.9523 | TN: 2996, FP: 150\n",
      "✅ Dataset 14 | Accuracy: 0.8741 | TN: 1395, FP: 201\n",
      "✅ Dataset 17 | Accuracy: 0.6494 | TN: 1343, FP: 725\n",
      "✅ Dataset 24 | Accuracy: 0.9007 | TN: 1987, FP: 219\n",
      "✅ Dataset 25 | Accuracy: 0.9686 | TN: 1881, FP: 61\n",
      "✅ Dataset 38 | Accuracy: 0.8426 | TN: 1788, FP: 334\n",
      "✅ Dataset 51 | Accuracy: 0.9247 | TN: 1793, FP: 146\n",
      "✅ Dataset 69 | Accuracy: 0.2721 | TN: 560, FP: 1498\n",
      "✅ Dataset 71 | Accuracy: 0.9653 | TN: 1837, FP: 66\n",
      "✅ Dataset 92 | Accuracy: 0.9076 | TN: 1375, FP: 140\n",
      "\n",
      "📊 === Final Results ===\n",
      "Average Accuracy: 0.8346\n",
      "Total TN: 19473, Total FP: 3751\n"
     ]
    }
   ],
   "source": [
    "\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "\n",
    "# === Dataset event table ===\n",
    "events = [\n",
    "    {\"dataset\": 3, \"start\": 52185, \"end\": 55198},\n",
    "    {\"dataset\": 13, \"start\": 50859, \"end\": 53865},\n",
    "    {\"dataset\": 14, \"start\": 52584, \"end\": 53620},\n",
    "    {\"dataset\": 17, \"start\": 52597, \"end\": 54513},\n",
    "    {\"dataset\": 24, \"start\": 52720, \"end\": 54714},\n",
    "    {\"dataset\": 25, \"start\": 52289, \"end\": 54135},\n",
    "    {\"dataset\": 38, \"start\": 52723, \"end\": 54546},\n",
    "    {\"dataset\": 51, \"start\": 52331, \"end\": 54003},\n",
    "    {\"dataset\": 69, \"start\": 52364, \"end\": 54380},\n",
    "    {\"dataset\": 71, \"start\": 52439, \"end\": 54455},\n",
    "    {\"dataset\": 92, \"start\": 52437, \"end\": 53778},\n",
    "]\n",
    "\n",
    "\n",
    "# === Base paths ===\n",
    "gt_base = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm A\\Wind Farm A\\datasets\" ##CARE Dataset for wind farm A\n",
    "pred_base = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm A\"    ##Our Processed Dataset for wind farm A\n",
    "\n",
    "\n",
    "# === Storage for average computation ===\n",
    "accuracies = []\n",
    "total_tn = 0\n",
    "total_fp = 0\n",
    "\n",
    "# === Loop through all events ===\n",
    "for event in events:\n",
    "    dataset_id = event[\"dataset\"]\n",
    "    event_start = event[\"start\"]\n",
    "    event_end = event[\"end\"]\n",
    "    \n",
    "    # Construct file paths\n",
    "    gt_path = os.path.join(gt_base, f\"{dataset_id}.csv\")\n",
    "    pred_path = os.path.join(pred_base, f\"{dataset_id}_WindFarm_A_predictions_lgb_smoothed.csv\")\n",
    "    \n",
    "    # Load CSVs\n",
    "    try:\n",
    "        gt_df = pd.read_csv(gt_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(pred_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Files for dataset {dataset_id} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Filter to prediction phase\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    # Remove all abnormal status ids from ground truth\n",
    "    gt_df = gt_df[~gt_df['status_type_id'].isin(abnormal_status_ids)].copy()\n",
    "\n",
    "    # Optional: Force GT inside event window to normal (if event assumed normal)\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'status_type_id'] = normal_status_id\n",
    "\n",
    "    # Assign anomaly label (0 = normal, 1 = anomaly)\n",
    "    gt_df['anomaly_label'] = gt_df['status_type_id'].apply(lambda x: 0 if x == normal_status_id else 1)\n",
    "\n",
    "    # Evaluate over entire prediction time frame\n",
    "    gt_eval_df = gt_df.copy()\n",
    "    pred_eval_df = pred_df.copy()\n",
    "\n",
    "    # Merge and classify predictions\n",
    "    merged_df = pd.merge(\n",
    "        gt_eval_df[['id', 'anomaly_label']],\n",
    "        pred_eval_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(lambda x: 0 if x == normal_status_id else 1)\n",
    "\n",
    "    # Compute TN, FP, Accuracy\n",
    "    tn = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 0))\n",
    "    fp = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 1))\n",
    "    accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    # Store results\n",
    "    accuracies.append(accuracy)\n",
    "    total_tn += tn\n",
    "    total_fp += fp\n",
    "\n",
    "    # Output per dataset\n",
    "    print(f\"✅ Dataset {dataset_id} | Accuracy: {accuracy:.4f} | TN: {tn}, FP: {fp}\")\n",
    "\n",
    "# === Final average results ===\n",
    "avg_accuracy_a = np.mean(accuracies) if accuracies else 0.0\n",
    "print(\"\\n📊 === Final Results ===\")\n",
    "print(f\"Average Accuracy: {avg_accuracy_a:.4f}\")\n",
    "print(f\"Total TN: {total_tn}, Total FP: {total_fp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325f38c-6e46-4a12-9a99-2fda2f8619a2",
   "metadata": {},
   "source": [
    "## Wind Farm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0d61f4-fa6d-4023-b880-a516481829ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 2 | Accuracy: 1.0000 | TN: 2160, FP: 0\n",
      "✅ Dataset 21 | Accuracy: 1.0000 | TN: 1269, FP: 0\n",
      "✅ Dataset 23 | Accuracy: 0.7281 | TN: 1269, FP: 474\n",
      "✅ Dataset 52 | Accuracy: 0.9993 | TN: 2728, FP: 2\n",
      "✅ Dataset 74 | Accuracy: 0.9990 | TN: 3016, FP: 3\n",
      "✅ Dataset 82 | Accuracy: 0.7382 | TN: 1762, FP: 625\n",
      "✅ Dataset 83 | Accuracy: 0.8213 | TN: 10561, FP: 2298\n",
      "✅ Dataset 86 | Accuracy: 1.0000 | TN: 2856, FP: 0\n",
      "✅ Dataset 87 | Accuracy: 0.8081 | TN: 2371, FP: 563\n",
      "\n",
      "📊 === Final Results ===\n",
      "Average Accuracy: 0.8993\n",
      "Total TN: 27992, Total FP: 3965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Constants ===\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "\n",
    "# === Dataset event table ===\n",
    "events = [\n",
    "    {\"dataset\": 2, \"start\": 52703, \"end\": 54629},\n",
    "    {\"dataset\": 21, \"start\": 52217, \"end\": 53513},\n",
    "    {\"dataset\": 23, \"start\": 52559, \"end\": 53965},\n",
    "    {\"dataset\": 52, \"start\": 52675, \"end\": 54691},\n",
    "    {\"dataset\": 74, \"start\": 52817, \"end\": 54737},\n",
    "    {\"dataset\": 82, \"start\": 52975, \"end\": 54703},\n",
    "    {\"dataset\": 83, \"start\": 52329, \"end\": 65433},\n",
    "    {\"dataset\": 86, \"start\": 52703, \"end\": 54621},\n",
    "    {\"dataset\": 87, \"start\": 52475, \"end\": 54779},\n",
    "]\n",
    "\n",
    "\n",
    "# === Base paths ===\n",
    "gt_base = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm B\\Wind Farm B\\datasets\" ## CARE Dataset for wind farm B\n",
    "pred_base = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm B\"      ## Our Processed Dataset for wind farm B\n",
    "\n",
    "accuracies = []\n",
    "total_tn = 0\n",
    "total_fp = 0\n",
    "\n",
    "# === Loop through all events ===\n",
    "for event in events:\n",
    "    dataset_id = event[\"dataset\"]\n",
    "    event_start = event[\"start\"]\n",
    "    event_end = event[\"end\"]\n",
    "    \n",
    "    # Construct file paths\n",
    "    gt_path = os.path.join(gt_base, f\"{dataset_id}.csv\")\n",
    "    pred_path = os.path.join(pred_base, f\"{dataset_id}_WindFarm_B_predictions_lgb_smoothed.csv\")\n",
    "    \n",
    "    # Load CSVs\n",
    "    try:\n",
    "        gt_df = pd.read_csv(gt_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(pred_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Files for dataset {dataset_id} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Filter to prediction phase\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    # Remove all abnormal status ids from ground truth\n",
    "    gt_df = gt_df[~gt_df['status_type_id'].isin(abnormal_status_ids)].copy()\n",
    "\n",
    "    # Optional: Force GT inside event window to normal (if event assumed normal)\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'status_type_id'] = normal_status_id\n",
    "\n",
    "    # Assign anomaly label (0 = normal, 1 = anomaly)\n",
    "    gt_df['anomaly_label'] = gt_df['status_type_id'].apply(lambda x: 0 if x == normal_status_id else 1)\n",
    "\n",
    "    # Evaluate over entire prediction time frame\n",
    "    gt_eval_df = gt_df.copy()\n",
    "    pred_eval_df = pred_df.copy()\n",
    "\n",
    "    # Merge and classify predictions\n",
    "    merged_df = pd.merge(\n",
    "        gt_eval_df[['id', 'anomaly_label']],\n",
    "        pred_eval_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(lambda x: 0 if x == normal_status_id else 1)\n",
    "\n",
    "    # Compute TN, FP, Accuracy\n",
    "    tn = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 0))\n",
    "    fp = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 1))\n",
    "    accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    # Store results\n",
    "    accuracies.append(accuracy)\n",
    "    total_tn += tn\n",
    "    total_fp += fp\n",
    "\n",
    "    # Output per dataset\n",
    "    print(f\"✅ Dataset {dataset_id} | Accuracy: {accuracy:.4f} | TN: {tn}, FP: {fp}\")\n",
    "\n",
    "# === Final average results ===\n",
    "avg_accuracy_b = np.mean(accuracies) if accuracies else 0.0\n",
    "print(\"\\n📊 === Final Results ===\")\n",
    "print(f\"Average Accuracy: {avg_accuracy_b:.4f}\")\n",
    "print(f\"Total TN: {total_tn}, Total FP: {total_fp}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b8642-7a39-4d87-88bc-bd1535f6b117",
   "metadata": {},
   "source": [
    "## Wind Farm C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d7204d-cc4c-4f94-add4-7fa9623d05b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 1 | Accuracy: 0.8887 | TN: 1885, FP: 236\n",
      "✅ Dataset 6 | Accuracy: 1.0000 | TN: 2118, FP: 0\n",
      "✅ Dataset 8 | Accuracy: 0.6841 | TN: 1516, FP: 700\n",
      "✅ Dataset 20 | Accuracy: 0.9691 | TN: 2415, FP: 77\n",
      "✅ Dataset 29 | Accuracy: 0.6494 | TN: 1482, FP: 800\n",
      "✅ Dataset 32 | Accuracy: 0.7191 | TN: 1743, FP: 681\n",
      "✅ Dataset 36 | Accuracy: 1.0000 | TN: 2847, FP: 0\n",
      "✅ Dataset 37 | Accuracy: 0.8426 | TN: 2040, FP: 381\n",
      "✅ Dataset 41 | Accuracy: 0.6561 | TN: 2749, FP: 1441\n",
      "✅ Dataset 43 | Accuracy: 0.7805 | TN: 1988, FP: 559\n",
      "✅ Dataset 46 | Accuracy: 1.0000 | TN: 2554, FP: 0\n",
      "✅ Dataset 48 | Accuracy: 0.8497 | TN: 2295, FP: 406\n",
      "✅ Dataset 50 | Accuracy: 0.5126 | TN: 1748, FP: 1662\n",
      "✅ Dataset 54 | Accuracy: 0.3563 | TN: 1054, FP: 1904\n",
      "✅ Dataset 56 | Accuracy: 0.9846 | TN: 2109, FP: 33\n",
      "✅ Dataset 57 | Accuracy: 0.9384 | TN: 2254, FP: 148\n",
      "✅ Dataset 58 | Accuracy: 0.8885 | TN: 1650, FP: 207\n",
      "✅ Dataset 59 | Accuracy: 0.7997 | TN: 2172, FP: 544\n",
      "✅ Dataset 60 | Accuracy: 0.4444 | TN: 1056, FP: 1320\n",
      "✅ Dataset 61 | Accuracy: 1.0000 | TN: 2919, FP: 0\n",
      "✅ Dataset 62 | Accuracy: 0.0000 | TN: 0, FP: 1026\n",
      "✅ Dataset 63 | Accuracy: 0.9510 | TN: 2174, FP: 112\n",
      "✅ Dataset 64 | Accuracy: 0.7091 | TN: 1309, FP: 537\n",
      "✅ Dataset 65 | Accuracy: 0.8280 | TN: 2749, FP: 571\n",
      "✅ Dataset 75 | Accuracy: 0.8711 | TN: 3028, FP: 448\n",
      "✅ Dataset 80 | Accuracy: 0.9008 | TN: 2097, FP: 231\n",
      "✅ Dataset 85 | Accuracy: 0.4484 | TN: 700, FP: 861\n",
      "✅ Dataset 88 | Accuracy: 0.8163 | TN: 2066, FP: 465\n",
      "✅ Dataset 89 | Accuracy: 0.9549 | TN: 2586, FP: 122\n",
      "✅ Dataset 93 | Accuracy: 0.9333 | TN: 3021, FP: 216\n",
      "✅ Dataset 94 | Accuracy: 0.9029 | TN: 2176, FP: 234\n",
      "\n",
      "📊 === Final Results ===\n",
      "Average Accuracy: 0.7832\n",
      "Total TN: 62500, Total FP: 15922\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Constants ===\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]\n",
    "\n",
    "# === Dataset event table ===\n",
    "events = [\n",
    "    {\"dataset\": 1, \"start\": 51552, \"end\": 53136},\n",
    "    {\"dataset\": 6, \"start\": 52560, \"end\": 54576},\n",
    "    {\"dataset\": 8, \"start\": 52560, \"end\": 54513},\n",
    "    {\"dataset\": 20, \"start\": 51696, \"end\": 53136},\n",
    "    {\"dataset\": 29, \"start\": 52704, \"end\": 54720},\n",
    "    {\"dataset\": 32, \"start\": 52560, \"end\": 54432},\n",
    "    {\"dataset\": 36, \"start\": 52704, \"end\": 54439},\n",
    "    {\"dataset\": 37, \"start\": 51552, \"end\": 53280},\n",
    "    {\"dataset\": 41, \"start\": 51552, \"end\": 55521},\n",
    "    {\"dataset\": 43, \"start\": 52992, \"end\": 54864},\n",
    "    {\"dataset\": 46, \"start\": 52560, \"end\": 54556},\n",
    "    {\"dataset\": 48, \"start\": 52848, \"end\": 54720},\n",
    "    {\"dataset\": 50, \"start\": 52128, \"end\": 54144},\n",
    "    {\"dataset\": 54, \"start\": 52992, \"end\": 54576},\n",
    "    {\"dataset\": 56, \"start\": 51120, \"end\": 53127},\n",
    "    {\"dataset\": 57, \"start\": 52992, \"end\": 54720},\n",
    "    {\"dataset\": 58, \"start\": 52992, \"end\": 54432},\n",
    "    {\"dataset\": 59, \"start\": 52128, \"end\": 54144},\n",
    "    {\"dataset\": 60, \"start\": 52416, \"end\": 54000},\n",
    "    {\"dataset\": 61, \"start\": 52992, \"end\": 55008},\n",
    "    {\"dataset\": 62, \"start\": 52416, \"end\": 53447},\n",
    "    {\"dataset\": 63, \"start\": 52704, \"end\": 54144},\n",
    "    {\"dataset\": 64, \"start\": 52560, \"end\": 54000},\n",
    "    {\"dataset\": 65, \"start\": 52992, \"end\": 55053},\n",
    "    {\"dataset\": 75, \"start\": 52992, \"end\": 55728},\n",
    "    {\"dataset\": 80, \"start\": 52560, \"end\": 54624},\n",
    "    {\"dataset\": 85, \"start\": 50832, \"end\": 52272},\n",
    "    {\"dataset\": 88, \"start\": 52704, \"end\": 54720},\n",
    "    {\"dataset\": 89, \"start\": 51840, \"end\": 53712},\n",
    "    {\"dataset\": 93, \"start\": 52704, \"end\": 55872},\n",
    "    {\"dataset\": 94, \"start\": 52416, \"end\": 53856},\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Base paths ===\n",
    "gt_base = r\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm C\\Wind Farm C\\datasets\" ## CARE Dataset for wind farm C\n",
    "pred_base = r\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm C\"  ## Our Final Processed DataSet for wind farm C\n",
    "\n",
    "\n",
    "# === Storage for average computation ===\n",
    "accuracies = []\n",
    "total_tn = 0\n",
    "total_fp = 0\n",
    "\n",
    "# === Loop through all events ===\n",
    "for event in events:\n",
    "    dataset_id = event[\"dataset\"]\n",
    "    event_start = event[\"start\"]\n",
    "    event_end = event[\"end\"]\n",
    "    \n",
    "    # Construct file paths\n",
    "    gt_path = os.path.join(gt_base, f\"{dataset_id}.csv\")\n",
    "    pred_path = os.path.join(pred_base, f\"{dataset_id}_WindFarm_C_predictions_lgb_smoothed.csv\")\n",
    "    \n",
    "    # Load CSVs\n",
    "    try:\n",
    "        gt_df = pd.read_csv(gt_path, delimiter=';')\n",
    "        pred_df = pd.read_csv(pred_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Files for dataset {dataset_id} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Filter to prediction phase\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    # Remove all abnormal status ids from ground truth\n",
    "    gt_df = gt_df[~gt_df['status_type_id'].isin(abnormal_status_ids)].copy()\n",
    "\n",
    "    # Optional: Force GT inside event window to normal (if event assumed normal)\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'status_type_id'] = normal_status_id\n",
    "\n",
    "    # Assign anomaly label (0 = normal, 1 = anomaly)\n",
    "    gt_df['anomaly_label'] = gt_df['status_type_id'].apply(lambda x: 0 if x == normal_status_id else 1)\n",
    "\n",
    "    # Evaluate over entire prediction time frame\n",
    "    gt_eval_df = gt_df.copy()\n",
    "    pred_eval_df = pred_df.copy()\n",
    "\n",
    "    # Merge and classify predictions\n",
    "    merged_df = pd.merge(\n",
    "        gt_eval_df[['id', 'anomaly_label']],\n",
    "        pred_eval_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(lambda x: 0 if x == normal_status_id else 1)\n",
    "\n",
    "    # Compute TN, FP, Accuracy\n",
    "    tn = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 0))\n",
    "    fp = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 1))\n",
    "    accuracy = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    # Store results\n",
    "    accuracies.append(accuracy)\n",
    "    total_tn += tn\n",
    "    total_fp += fp\n",
    "\n",
    "    # Output per dataset\n",
    "    print(f\"✅ Dataset {dataset_id} | Accuracy: {accuracy:.4f} | TN: {tn}, FP: {fp}\")\n",
    "\n",
    "# === Final average results ===\n",
    "avg_accuracy_c = np.mean(accuracies) if accuracies else 0.0\n",
    "print(\"\\n📊 === Final Results ===\")\n",
    "print(f\"Average Accuracy: {avg_accuracy_c:.4f}\")\n",
    "print(f\"Total TN: {total_tn}, Total FP: {total_fp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21c9ad-7d7f-4a50-bfb1-1a4ca9d88de9",
   "metadata": {},
   "source": [
    "## Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7102499-9708-48fe-8133-42c56876250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === Final Results ===\n",
      "Average Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = ((avg_accuracy_a * 11) + (avg_accuracy_b * 9) + (avg_accuracy_c * 31))/51\n",
    "print(\"\\n📊 === Final Results ===\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
