{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9f2775-c3b5-44b7-8379-24a933497a71",
   "metadata": {},
   "source": [
    "## Coverage Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f83b6-f552-4e10-8d13-c942329c0ad2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c22bcf-4f67-464a-bfa4-6e0fbb117457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370bdc3b-66b5-408f-af81-fb505630496b",
   "metadata": {},
   "source": [
    "## Wind Farm A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af802217-9ad2-46de-9d37-66f818ad0bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ Processing Dataset 0...\n",
      "âœ… Dataset 0: F_0.5-Score = 0.5657 | TP=658, FN=1354, FP=293\n",
      "\n",
      "ðŸ“‚ Processing Dataset 10...\n",
      "âœ… Dataset 10: F_0.5-Score = 0.2975 | TP=89, FN=891, FP=40\n",
      "\n",
      "ðŸ“‚ Processing Dataset 22...\n",
      "âœ… Dataset 22: F_0.5-Score = 0.5589 | TP=203, FN=801, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 26...\n",
      "âœ… Dataset 26: F_0.5-Score = 0.1330 | TP=30, FN=978, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 40...\n",
      "âœ… Dataset 40: F_0.5-Score = 0.7625 | TP=1565, FN=2437, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 42...\n",
      "âœ… Dataset 42: F_0.5-Score = 0.5804 | TP=218, FN=788, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 68...\n",
      "âœ… Dataset 68: F_0.5-Score = 0.9286 | TP=1455, FN=559, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 72...\n",
      "âœ… Dataset 72: F_0.5-Score = 0.0414 | TP=11, FN=997, FP=69\n",
      "\n",
      "ðŸ“‚ Processing Dataset 73...\n",
      "âœ… Dataset 73: F_0.5-Score = 0.4632 | TP=249, FN=759, FP=171\n",
      "\n",
      "ðŸ”¥ Average F_0.5-Score across all datasets of wind farm A: 0.4812\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of datasets with their event start and end IDs\n",
    "datasets = [\n",
    "    (0, 52436, 54447),\n",
    "    (10, 52611, 53591),\n",
    "    (22, 51888, 52892),\n",
    "    (26, 52261, 53269),\n",
    "    (40, 51363, 55870),\n",
    "    (42, 52303, 53309),\n",
    "    (68, 52063, 54076),\n",
    "    (72, 52497, 53505),\n",
    "    (73, 52745, 53753),\n",
    "]\n",
    "# Status IDs\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]  # Adjust based on your definition\n",
    "\n",
    "\n",
    "# F-beta parameter\n",
    "beta = 0.5\n",
    "\n",
    "\n",
    "f_beta_scores = []\n",
    "\n",
    "for dataset_id, event_start, event_end in datasets:\n",
    "    print(f\"\\nðŸ“‚ Processing Dataset {dataset_id}...\")\n",
    "\n",
    "    # Construct file paths\n",
    "    ground_truth_path = fr\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm A\\Wind Farm A\\datasets\\{dataset_id}.csv\"\n",
    "    predicted_path = fr\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm A\\{dataset_id}_WindFarm_A_predictions_lgb_smoothed.csv\"\n",
    "\n",
    "    # Load CSVs\n",
    "    gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "    pred_df = pd.read_csv(predicted_path)\n",
    "\n",
    "    # Filter to prediction data\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    # Remove abnormal status types from ground truth\n",
    "    gt_df = gt_df[~gt_df['status_type_id'].isin(abnormal_status_ids)]\n",
    "\n",
    "    # Assign anomaly labels\n",
    "    gt_df['anomaly_label'] = 0\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'anomaly_label'] = 1\n",
    "\n",
    "    # Merge ground truth with predictions\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'anomaly_label']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Map predictions to binary anomaly labels\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 1 if x != normal_status_id else 0\n",
    "    )\n",
    "\n",
    "    # Compute TP, FN, FP\n",
    "    tp = np.sum((merged_df['anomaly_label'] == 1) & (merged_df['pred_label'] == 1))\n",
    "    fn = np.sum((merged_df['anomaly_label'] == 1) & (merged_df['pred_label'] == 0))\n",
    "    fp = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 1))\n",
    "\n",
    "    # Compute F_beta score\n",
    "    numerator = (1 + beta ** 2) * tp\n",
    "    denominator = numerator + (beta ** 2) * fn + fp\n",
    "    coverage_score = numerator / denominator if denominator > 0 else 0\n",
    "\n",
    "    f_beta_scores.append(coverage_score)\n",
    "\n",
    "    print(f\"âœ… Dataset {dataset_id}: F_{beta}-Score = {coverage_score:.4f} | TP={tp}, FN={fn}, FP={fp}\")\n",
    "\n",
    "# Average F_beta Score\n",
    "avg_f_beta_a = np.mean(f_beta_scores)\n",
    "print(f\"\\nðŸ”¥ Average F_{beta}-Score across all datasets of wind farm A: {avg_f_beta_a:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6836e64-d055-4121-b57b-51fa0dd895a5",
   "metadata": {},
   "source": [
    "## Wind Farm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd63aa3-847e-49f1-b607-895492af3a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ Processing Dataset 7...\n",
      "âœ… Dataset 7: F_0.5-Score = 0.4882 | TP=775, FN=3435, FP=157\n",
      "\n",
      "ðŸ“‚ Processing Dataset 19...\n",
      "âœ… Dataset 19: F_0.5-Score = 0.8093 | TP=2855, FN=0, FP=841\n",
      "\n",
      "ðŸ“‚ Processing Dataset 27...\n",
      "âœ… Dataset 27: F_0.5-Score = 0.6237 | TP=2092, FN=6312, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 34...\n",
      "âœ… Dataset 34: F_0.5-Score = 0.6528 | TP=1754, FN=1292, FP=843\n",
      "\n",
      "ðŸ“‚ Processing Dataset 53...\n",
      "âœ… Dataset 53: F_0.5-Score = 0.9386 | TP=4303, FN=1408, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 77...\n",
      "âœ… Dataset 77: F_0.5-Score = 0.9646 | TP=7862, FN=0, FP=361\n",
      "\n",
      "ðŸ”¥ Average F_0.5-Score across all datasets of wind farm B: 0.7462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of datasets with their event start and end IDs\n",
    "datasets = [\n",
    "    (7, 52703, 57167),\n",
    "    (19, 52673, 55553),\n",
    "    (27, 52619, 61403),\n",
    "    (34, 52531, 55699),\n",
    "    (53, 52559, 58606),\n",
    "    (77, 52991, 61631),\n",
    "]\n",
    "\n",
    "# Status IDs\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]  # Adjust based on your definition\n",
    "\n",
    "# F-beta parameter\n",
    "beta = 0.5\n",
    "\n",
    "f_beta_scores = []\n",
    "\n",
    "for dataset_id, event_start, event_end in datasets:\n",
    "    print(f\"\\nðŸ“‚ Processing Dataset {dataset_id}...\")\n",
    "\n",
    "    # Construct file paths\n",
    "    ground_truth_path = fr\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm B\\Wind Farm B\\datasets\\{dataset_id}.csv\"\n",
    "    predicted_path = fr\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm B\\{dataset_id}_WindFarm_B_predictions_lgb_smoothed.csv\"\n",
    "\n",
    "    # Load CSVs\n",
    "    gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "    pred_df = pd.read_csv(predicted_path)\n",
    "\n",
    "    # Filter to prediction data\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    # Remove abnormal status types from ground truth\n",
    "    gt_df = gt_df[~gt_df['status_type_id'].isin(abnormal_status_ids)]\n",
    "\n",
    "    # Assign anomaly labels\n",
    "    gt_df['anomaly_label'] = 0\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'anomaly_label'] = 1\n",
    "\n",
    "    # Merge ground truth with predictions\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'anomaly_label']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Map predictions to binary anomaly labels\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 1 if x != normal_status_id else 0\n",
    "    )\n",
    "\n",
    "    # Compute TP, FN, FP\n",
    "    tp = np.sum((merged_df['anomaly_label'] == 1) & (merged_df['pred_label'] == 1))\n",
    "    fn = np.sum((merged_df['anomaly_label'] == 1) & (merged_df['pred_label'] == 0))\n",
    "    fp = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 1))\n",
    "\n",
    "    # Compute F_beta score\n",
    "    numerator = (1 + beta ** 2) * tp\n",
    "    denominator = numerator + (beta ** 2) * fn + fp\n",
    "    coverage_score = numerator / denominator if denominator > 0 else 0\n",
    "\n",
    "    f_beta_scores.append(coverage_score)\n",
    "\n",
    "    print(f\"âœ… Dataset {dataset_id}: F_{beta}-Score = {coverage_score:.4f} | TP={tp}, FN={fn}, FP={fp}\")\n",
    "\n",
    "# Average F_beta Score\n",
    "avg_f_beta_b = np.mean(f_beta_scores)\n",
    "print(f\"\\nðŸ”¥ Average F_{beta}-Score across all datasets of wind farm B: {avg_f_beta_b:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89339f5b-7827-4654-bd91-a577e79d5690",
   "metadata": {},
   "source": [
    "## Wind Farm C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b170fa03-7d77-4992-a90a-9b75dd6a5bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ Processing Dataset 4...\n",
      "âœ… Dataset 4: F_0.5-Score = 0.2289 | TP=236, FN=2359, FP=404\n",
      "\n",
      "ðŸ“‚ Processing Dataset 5...\n",
      "âœ… Dataset 5: F_0.5-Score = 0.5920 | TP=110, FN=135, FP=61\n",
      "\n",
      "ðŸ“‚ Processing Dataset 9...\n",
      "âœ… Dataset 9: F_0.5-Score = 0.5154 | TP=514, FN=2372, FP=11\n",
      "\n",
      "ðŸ“‚ Processing Dataset 11...\n",
      "âœ… Dataset 11: F_0.5-Score = 1.0000 | TP=2101, FN=0, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 12...\n",
      "âœ… Dataset 12: F_0.5-Score = 0.9285 | TP=2949, FN=0, FP=284\n",
      "\n",
      "ðŸ“‚ Processing Dataset 15...\n",
      "âœ… Dataset 15: F_0.5-Score = 0.5908 | TP=608, FN=1818, FP=72\n",
      "\n",
      "ðŸ“‚ Processing Dataset 16...\n",
      "âœ… Dataset 16: F_0.5-Score = 0.7203 | TP=137, FN=166, FP=25\n",
      "\n",
      "ðŸ“‚ Processing Dataset 18...\n",
      "âœ… Dataset 18: F_0.5-Score = 0.7161 | TP=227, FN=326, FP=31\n",
      "\n",
      "ðŸ“‚ Processing Dataset 28...\n",
      "âœ… Dataset 28: F_0.5-Score = 0.3418 | TP=257, FN=2118, FP=89\n",
      "\n",
      "ðŸ“‚ Processing Dataset 30...\n",
      "âœ… Dataset 30: F_0.5-Score = 0.2727 | TP=74, FN=359, FP=157\n",
      "\n",
      "ðŸ“‚ Processing Dataset 31...\n",
      "âœ… Dataset 31: F_0.5-Score = 0.0647 | TP=32, FN=192, FP=530\n",
      "\n",
      "ðŸ“‚ Processing Dataset 33...\n",
      "âœ… Dataset 33: F_0.5-Score = 0.4858 | TP=301, FN=1521, FP=18\n",
      "\n",
      "ðŸ“‚ Processing Dataset 35...\n",
      "âœ… Dataset 35: F_0.5-Score = 0.3096 | TP=73, FN=814, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 39...\n",
      "âœ… Dataset 39: F_0.5-Score = 0.1991 | TP=27, FN=215, FP=82\n",
      "\n",
      "ðŸ“‚ Processing Dataset 44...\n",
      "âœ… Dataset 44: F_0.5-Score = 0.5925 | TP=2014, FN=6774, FP=38\n",
      "\n",
      "ðŸ“‚ Processing Dataset 47...\n",
      "âœ… Dataset 47: F_0.5-Score = 0.2870 | TP=276, FN=416, FP=753\n",
      "\n",
      "ðŸ“‚ Processing Dataset 49...\n",
      "âœ… Dataset 49: F_0.5-Score = 0.4191 | TP=128, FN=467, FP=105\n",
      "\n",
      "ðŸ“‚ Processing Dataset 55...\n",
      "âœ… Dataset 55: F_0.5-Score = 0.5348 | TP=978, FN=1393, FP=715\n",
      "\n",
      "ðŸ“‚ Processing Dataset 66...\n",
      "âœ… Dataset 66: F_0.5-Score = 0.1708 | TP=139, FN=29, FP=836\n",
      "\n",
      "ðŸ“‚ Processing Dataset 67...\n",
      "âœ… Dataset 67: F_0.5-Score = 0.6965 | TP=2822, FN=5311, FP=209\n",
      "\n",
      "ðŸ“‚ Processing Dataset 70...\n",
      "âœ… Dataset 70: F_0.5-Score = 0.7788 | TP=1101, FN=1532, FP=8\n",
      "\n",
      "ðŸ“‚ Processing Dataset 76...\n",
      "âœ… Dataset 76: F_0.5-Score = 0.0000 | TP=0, FN=192, FP=157\n",
      "\n",
      "ðŸ“‚ Processing Dataset 78...\n",
      "âœ… Dataset 78: F_0.5-Score = 0.8023 | TP=112, FN=138, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 79...\n",
      "âœ… Dataset 79: F_0.5-Score = 0.0000 | TP=0, FN=169, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 81...\n",
      "âœ… Dataset 81: F_0.5-Score = 0.0000 | TP=0, FN=197, FP=0\n",
      "\n",
      "ðŸ“‚ Processing Dataset 90...\n",
      "âœ… Dataset 90: F_0.5-Score = 0.5421 | TP=299, FN=1167, FP=24\n",
      "\n",
      "ðŸ“‚ Processing Dataset 91...\n",
      "âœ… Dataset 91: F_0.5-Score = 0.4971 | TP=683, FN=1779, FP=419\n",
      "\n",
      "ðŸ”¥ Average F_0.5-Score across all datasets of wind farm C: 0.4551\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of datasets with their event start and end IDs\n",
    "datasets = [\n",
    "    (4, 52992, 55728),\n",
    "    (5, 52272, 52794),\n",
    "    (9, 52992, 56028),\n",
    "    (11, 52416, 55572),\n",
    "    (12, 52560, 55818),\n",
    "    (15, 51984, 54432),\n",
    "    (16, 51264, 53423),\n",
    "    (18, 51408, 51983),\n",
    "    (28, 52704, 55629),\n",
    "    (30, 52560, 55822),\n",
    "    (31, 52848, 53868),\n",
    "    (33, 52848, 55728),\n",
    "    (35, 51696, 52614),\n",
    "    (39, 52848, 53582),\n",
    "    (44, 52704, 62138),\n",
    "    (47, 52416, 53128),\n",
    "    (49, 51840, 52437),\n",
    "    (55, 52848, 55320),\n",
    "    (66, 51696, 52638),\n",
    "    (67, 52704, 61056),\n",
    "    (70, 52560, 55461),\n",
    "    (76, 51552, 51797),\n",
    "    (78, 52560, 52857),\n",
    "    (79, 52704, 52992),\n",
    "    (81, 52704, 53067),\n",
    "    (90, 52848, 54591),\n",
    "    (91, 52704, 55599),\n",
    "]\n",
    "\n",
    "# Status IDs\n",
    "normal_status_id = 0\n",
    "abnormal_status_ids = [1, 3, 4, 5]  # Adjust based on your definition\n",
    "\n",
    "\n",
    "# F-beta parameter\n",
    "beta = 0.5\n",
    "\n",
    "f_beta_scores = []\n",
    "\n",
    "for dataset_id, event_start, event_end in datasets:\n",
    "    print(f\"\\nðŸ“‚ Processing Dataset {dataset_id}...\")\n",
    "\n",
    "\n",
    "    # Construct file paths\n",
    "    ground_truth_path = fr\"D:\\Master Thesis New Data Set\\CARE DATA SET\\CARE_To_Compare\\Wind Farm C\\Wind Farm C\\datasets\\{dataset_id}.csv\"\n",
    "    predicted_path = fr\"D:\\Master Thesis New Data Set\\Final Processed Dataset\\Wind Farm C\\{dataset_id}_WindFarm_C_predictions_lgb_smoothed.csv\"\n",
    "\n",
    "    # Load CSVs\n",
    "    gt_df = pd.read_csv(ground_truth_path, delimiter=';')\n",
    "    pred_df = pd.read_csv(predicted_path)\n",
    "\n",
    "    # Filter to prediction data\n",
    "    gt_df = gt_df[gt_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "    pred_df = pred_df[pred_df['train_test'].str.lower() == 'prediction'].copy()\n",
    "\n",
    "    # Remove abnormal status types from ground truth\n",
    "    gt_df = gt_df[~gt_df['status_type_id'].isin(abnormal_status_ids)]\n",
    "\n",
    "    # Assign anomaly labels\n",
    "    gt_df['anomaly_label'] = 0\n",
    "    event_mask = (gt_df['id'] >= event_start) & (gt_df['id'] <= event_end)\n",
    "    gt_df.loc[event_mask, 'anomaly_label'] = 1\n",
    "\n",
    "    # Merge ground truth with predictions\n",
    "    merged_df = pd.merge(\n",
    "        gt_df[['id', 'anomaly_label']],\n",
    "        pred_df[['id', 'predicted_status_type_binary_smooth']],\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Map predictions to binary anomaly labels\n",
    "    merged_df['pred_label'] = merged_df['predicted_status_type_binary_smooth'].apply(\n",
    "        lambda x: 1 if x != normal_status_id else 0\n",
    "    )\n",
    "\n",
    "    # Compute TP, FN, FP\n",
    "    tp = np.sum((merged_df['anomaly_label'] == 1) & (merged_df['pred_label'] == 1))\n",
    "    fn = np.sum((merged_df['anomaly_label'] == 1) & (merged_df['pred_label'] == 0))\n",
    "    fp = np.sum((merged_df['anomaly_label'] == 0) & (merged_df['pred_label'] == 1))\n",
    "\n",
    "    # Compute F_beta score\n",
    "    numerator = (1 + beta ** 2) * tp\n",
    "    denominator = numerator + (beta ** 2) * fn + fp\n",
    "    coverage_score = numerator / denominator if denominator > 0 else 0\n",
    "\n",
    "    f_beta_scores.append(coverage_score)\n",
    "\n",
    "    print(f\"âœ… Dataset {dataset_id}: F_{beta}-Score = {coverage_score:.4f} | TP={tp}, FN={fn}, FP={fp}\")\n",
    "\n",
    "# Average F_beta Score\n",
    "avg_f_beta_c = np.mean(f_beta_scores)\n",
    "print(f\"\\nðŸ”¥ Average F_{beta}-Score across all datasets of wind farm C: {avg_f_beta_c:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432857a7-2894-47cd-a4e1-f559432697d1",
   "metadata": {},
   "source": [
    "## Overall Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09b33d5-75a4-473a-bcc9-c8950777d622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¥ Average F_0.5-Score across all datasets: 0.5023\n"
     ]
    }
   ],
   "source": [
    "avg_f_beta_final = ((avg_f_beta_a * 9) + (avg_f_beta_b * 6) + (avg_f_beta_c * 27))/42     ##For all windfarms\n",
    "print(f\"\\nðŸ”¥ Average F_{beta}-Score across all datasets: {avg_f_beta_final:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
